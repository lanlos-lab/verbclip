{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch, clip\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "setting_name = '32' # '32' for ViT-B/32, '14' for ViT-L/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images: 11750\n"
     ]
    }
   ],
   "source": [
    "# for copyright purposes, the iamges are not provided\n",
    "# in this repository\n",
    "data_path = Path('path/to/images/folder')\n",
    "\n",
    "image_to_encode = list(data_path.glob('*.jpg'))\n",
    "print(f'Number of images: {len(image_to_encode)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:22<00:00,  2.25s/it]\n"
     ]
    }
   ],
   "source": [
    "embeddings = []\n",
    "names = []\n",
    "image_to_encode = image_to_encode\n",
    "batch_size = 128\n",
    "for fs in tqdm([image_to_encode[i:i+batch_size] for i in range(0, len(image_to_encode), batch_size)]):\n",
    "    images = [Image.open(f) for f in fs]\n",
    "    image_input = torch.stack([preprocess(image) for image in images]).to(device)\n",
    "    with torch.no_grad():\n",
    "        image_features = model.encode_image(image_input)\n",
    "    embeddings.append(image_features)\n",
    "    # modify the following line if a different naming convention is used\n",
    "    names.extend([f.stem for f in fs]) \n",
    "embeddings = torch.cat(embeddings).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(data_path.parent / f'embeddings/txt_emb_{setting_name}.pkl', 'wb') as f:\n",
    "    pickle.dump({name: emb.squeeze() for name, emb in zip(names, embeddings)}, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnlp31013m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
